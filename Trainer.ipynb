{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trainer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJvOHlU5PpoX",
        "colab_type": "code",
        "outputId": "5e3a8c89-0c28-4a07-8ec8-425fb780193e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvCZyuQGPt2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_Xj-3ZiP2I9",
        "colab_type": "code",
        "outputId": "184f0515-a677-4970-be0c-832ed2a0a918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data = pd.read_csv('drive/My Drive/dataset/greetings_small.csv')\n",
        "data = data['greetings'].str.replace('[^\\w\\s]',' ')\n",
        "data = data.str.lower()\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       тебе желаю море счастья улыбок  солнца и тепла...\n",
              "1       с днем рождения поздравляюи желаю день за днем...\n",
              "2       поздравляю с днем рождения  пусть жизнь дарит ...\n",
              "3       пусть в жизни будет все  что нужно здоровье  м...\n",
              "4       с днем рожденья поздравляюи от всей души желаю...\n",
              "                              ...                        \n",
              "4992    желаю  по жизни шагать лишь вперёд упорством с...\n",
              "4993    пускай удача не отступит легко поможет в каждо...\n",
              "4994    желаю искромётного успеха чтоб воплощались все...\n",
              "4995    желаю громкого везения пускай успехи валят с н...\n",
              "4996    желаю море процветания во всех задачах   продв...\n",
              "Name: greetings, Length: 4997, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgelSHFqW_J9",
        "colab_type": "code",
        "outputId": "c6f4ac4f-851b-4ea8-f4ef-a0a154b1745c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# Neural Net Layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "# Neural Net Training\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wefYyYsAmMR6",
        "colab_type": "code",
        "outputId": "fc5bdf9f-3e68-4629-e7be-3c691eed4075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "max_words = 50000 # Max size of the dictionary\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(data.values)\n",
        "sequences = tokenizer.texts_to_sequences(data.values)\n",
        "print(sequences[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[12, 7, 64, 14, 89, 133, 1, 70, 6, 25, 82, 96, 566, 53, 68, 447, 1340, 3, 2, 111, 11, 38, 43, 287, 188, 1, 271, 80, 189, 77, 73, 305, 547, 168, 28, 128, 1155, 1636, 632, 331, 1, 3, 9, 8723, 17, 694, 36, 882], [5, 15, 16, 369, 7, 8, 68, 8724, 2422, 1, 219, 137, 115, 68, 915, 97, 22, 28, 35, 90, 1, 70, 6, 189, 143, 2051, 119, 84, 55, 3, 945, 11, 98, 1095, 1, 23, 2221, 1519, 448, 158, 172, 209], [33, 5, 15, 16, 3, 25, 276, 12, 98, 116, 458, 1, 183, 10, 85, 1341, 2052, 1, 476, 122, 7, 20, 2, 548, 111, 9, 3642, 34, 1, 1520, 1, 3, 17, 663, 38, 2423, 497, 2053, 80, 1, 527, 349], [3, 2, 21, 11, 10, 30, 382, 78, 114, 46, 1, 489, 4, 5761, 3, 72, 53, 1342, 106, 47, 3, 34, 11, 1897, 39, 549, 1, 31, 8725, 7, 35, 272, 4451, 1755, 822, 1, 161], [5, 15, 27, 369, 26, 125, 63, 5762, 23, 94, 20, 535, 66, 58, 90, 3, 30, 435, 695, 102, 19, 34, 282, 1430, 175, 3643, 220, 3, 4, 2693, 1010, 2, 111, 3, 332, 567, 2, 764, 11, 188, 155, 600, 1155, 96, 285, 33]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFpxQEFcmNHT",
        "colab_type": "code",
        "outputId": "7ab97a15-14c4-4dd7-adbd-8b62e12bcdf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = [item for sublist in sequences for item in sublist]\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "print('Vocabulary size in this corpus: ', vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size in this corpus:  23691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbFMpIa2muLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_len = 13\n",
        "pred_len = 1\n",
        "train_len = sentence_len - pred_len\n",
        "seq = []\n",
        "# Sliding window to generate train data\n",
        "for i in range(len(text)-sentence_len):\n",
        "    seq.append(text[i:i+sentence_len])\n",
        "# Reverse dictionary to decode tokenized sequences back to words\n",
        "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTCrAkhfmxIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = []\n",
        "trainy = []\n",
        "for i in seq:\n",
        "    trainX.append(i[:train_len])\n",
        "    trainy.append(i[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL4d3LDOm04f",
        "colab_type": "code",
        "outputId": "3d2746aa-855c-4770-daaa-c1e2e251fb21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size+1, 50, input_length=train_len),\n",
        "    LSTM(150, return_sequences=True),\n",
        "    LSTM(150),\n",
        "    Dense(150, activation='relu'),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I83VMusm4RV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy import array\n",
        "\n",
        "\n",
        "# model.fit(np.asarray(trainX),\n",
        "#          pd.get_dummies(np.asarray(trainy)),\n",
        "#          epochs = 500,\n",
        "#          batch_size = 10240,\n",
        "#          callbacks = callbacks_list,\n",
        "#          verbose = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v01070Sm7ly",
        "colab_type": "code",
        "outputId": "3c062945-ac12-4ec0-ce9d-66fb39db538e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(np.asarray(trainX), pd.get_dummies(np.asarray(trainy)), batch_size=128, epochs=300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 210282 samples\n",
            "Epoch 1/300\n",
            "210282/210282 [==============================] - 70s 331us/sample - loss: 7.3245 - acc: 0.0512\n",
            "Epoch 2/300\n",
            "210282/210282 [==============================] - 67s 317us/sample - loss: 6.9259 - acc: 0.0714\n",
            "Epoch 3/300\n",
            "210282/210282 [==============================] - 67s 320us/sample - loss: 6.6137 - acc: 0.0821\n",
            "Epoch 4/300\n",
            "210282/210282 [==============================] - 67s 319us/sample - loss: 6.3921 - acc: 0.0895\n",
            "Epoch 5/300\n",
            "210282/210282 [==============================] - 67s 317us/sample - loss: 6.1982 - acc: 0.0958\n",
            "Epoch 6/300\n",
            "210282/210282 [==============================] - 66s 316us/sample - loss: 6.0167 - acc: 0.1026\n",
            "Epoch 7/300\n",
            "210282/210282 [==============================] - 66s 315us/sample - loss: 5.8441 - acc: 0.1068\n",
            "Epoch 8/300\n",
            "210282/210282 [==============================] - 67s 317us/sample - loss: 5.6851 - acc: 0.1123\n",
            "Epoch 9/300\n",
            "210282/210282 [==============================] - 67s 317us/sample - loss: 5.5374 - acc: 0.1171\n",
            "Epoch 10/300\n",
            "210282/210282 [==============================] - 66s 313us/sample - loss: 5.3987 - acc: 0.1215\n",
            "Epoch 11/300\n",
            "210282/210282 [==============================] - 66s 312us/sample - loss: 5.2633 - acc: 0.1267\n",
            "Epoch 12/300\n",
            "210282/210282 [==============================] - 65s 311us/sample - loss: 5.1318 - acc: 0.1316\n",
            "Epoch 13/300\n",
            "210282/210282 [==============================] - 65s 309us/sample - loss: 5.0024 - acc: 0.1366\n",
            "Epoch 14/300\n",
            "210282/210282 [==============================] - 66s 312us/sample - loss: 4.8775 - acc: 0.1416\n",
            "Epoch 15/300\n",
            "210282/210282 [==============================] - 65s 309us/sample - loss: 4.7520 - acc: 0.1474\n",
            "Epoch 16/300\n",
            "210282/210282 [==============================] - 65s 308us/sample - loss: 4.6243 - acc: 0.1545\n",
            "Epoch 17/300\n",
            "210282/210282 [==============================] - 65s 309us/sample - loss: 4.4921 - acc: 0.1638\n",
            "Epoch 18/300\n",
            "210282/210282 [==============================] - 64s 305us/sample - loss: 4.3669 - acc: 0.1746\n",
            "Epoch 19/300\n",
            "210282/210282 [==============================] - 65s 308us/sample - loss: 4.2463 - acc: 0.1859\n",
            "Epoch 20/300\n",
            "210282/210282 [==============================] - 64s 306us/sample - loss: 4.1357 - acc: 0.1990\n",
            "Epoch 21/300\n",
            "210282/210282 [==============================] - 68s 324us/sample - loss: 4.0299 - acc: 0.2130\n",
            "Epoch 22/300\n",
            "210282/210282 [==============================] - 69s 330us/sample - loss: 3.9308 - acc: 0.2262\n",
            "Epoch 23/300\n",
            "210282/210282 [==============================] - 70s 335us/sample - loss: 3.8374 - acc: 0.2385\n",
            "Epoch 24/300\n",
            "210282/210282 [==============================] - 69s 328us/sample - loss: 3.7518 - acc: 0.2509\n",
            "Epoch 25/300\n",
            "210282/210282 [==============================] - 69s 329us/sample - loss: 3.6620 - acc: 0.2640\n",
            "Epoch 26/300\n",
            "210282/210282 [==============================] - 68s 325us/sample - loss: 3.5842 - acc: 0.2740\n",
            "Epoch 27/300\n",
            "210282/210282 [==============================] - 64s 305us/sample - loss: 3.5049 - acc: 0.2868\n",
            "Epoch 28/300\n",
            "210282/210282 [==============================] - 64s 305us/sample - loss: 3.4296 - acc: 0.2983\n",
            "Epoch 29/300\n",
            "210282/210282 [==============================] - 64s 302us/sample - loss: 3.3569 - acc: 0.3094\n",
            "Epoch 30/300\n",
            "210282/210282 [==============================] - 64s 304us/sample - loss: 3.2855 - acc: 0.3200\n",
            "Epoch 31/300\n",
            "210282/210282 [==============================] - 64s 305us/sample - loss: 3.2140 - acc: 0.3311\n",
            "Epoch 32/300\n",
            "210282/210282 [==============================] - 64s 306us/sample - loss: 3.1459 - acc: 0.3433\n",
            "Epoch 33/300\n",
            "210282/210282 [==============================] - 64s 305us/sample - loss: 3.0816 - acc: 0.3522\n",
            "Epoch 34/300\n",
            "210282/210282 [==============================] - 64s 304us/sample - loss: 3.0164 - acc: 0.3632\n",
            "Epoch 35/300\n",
            "210282/210282 [==============================] - 64s 304us/sample - loss: 2.9490 - acc: 0.3750\n",
            "Epoch 36/300\n",
            "210282/210282 [==============================] - 64s 306us/sample - loss: 2.8919 - acc: 0.3858\n",
            "Epoch 37/300\n",
            "210282/210282 [==============================] - 64s 306us/sample - loss: 2.8312 - acc: 0.3952\n",
            "Epoch 38/300\n",
            "210282/210282 [==============================] - 64s 305us/sample - loss: 2.7692 - acc: 0.4055\n",
            "Epoch 39/300\n",
            "210282/210282 [==============================] - 64s 303us/sample - loss: 2.7124 - acc: 0.4160\n",
            "Epoch 40/300\n",
            "210282/210282 [==============================] - 63s 302us/sample - loss: 2.6523 - acc: 0.4258\n",
            "Epoch 41/300\n",
            "210282/210282 [==============================] - 64s 304us/sample - loss: 2.5982 - acc: 0.4351\n",
            "Epoch 42/300\n",
            "210282/210282 [==============================] - 65s 307us/sample - loss: 2.5436 - acc: 0.4452\n",
            "Epoch 43/300\n",
            "210282/210282 [==============================] - 64s 305us/sample - loss: 2.4888 - acc: 0.4551\n",
            "Epoch 44/300\n",
            "210282/210282 [==============================] - 64s 305us/sample - loss: 2.4362 - acc: 0.4654\n",
            "Epoch 45/300\n",
            "210282/210282 [==============================] - 64s 303us/sample - loss: 2.3853 - acc: 0.4756\n",
            "Epoch 46/300\n",
            "210282/210282 [==============================] - 64s 307us/sample - loss: 2.3391 - acc: 0.4839\n",
            "Epoch 47/300\n",
            "210282/210282 [==============================] - 65s 307us/sample - loss: 2.2888 - acc: 0.4932\n",
            "Epoch 48/300\n",
            "210282/210282 [==============================] - 64s 307us/sample - loss: 2.2415 - acc: 0.5030\n",
            "Epoch 49/300\n",
            "210282/210282 [==============================] - 65s 311us/sample - loss: 2.1940 - acc: 0.5106\n",
            "Epoch 50/300\n",
            "210282/210282 [==============================] - 69s 329us/sample - loss: 2.1518 - acc: 0.5193\n",
            "Epoch 51/300\n",
            "210282/210282 [==============================] - 69s 328us/sample - loss: 2.1059 - acc: 0.5273\n",
            "Epoch 52/300\n",
            "210282/210282 [==============================] - 69s 328us/sample - loss: 2.0674 - acc: 0.5348\n",
            "Epoch 53/300\n",
            "210282/210282 [==============================] - 68s 324us/sample - loss: 2.0238 - acc: 0.5428\n",
            "Epoch 54/300\n",
            "210282/210282 [==============================] - 64s 306us/sample - loss: 1.9814 - acc: 0.5529\n",
            "Epoch 55/300\n",
            "210282/210282 [==============================] - 64s 304us/sample - loss: 1.9449 - acc: 0.5592\n",
            "Epoch 56/300\n",
            "210282/210282 [==============================] - 63s 300us/sample - loss: 1.9039 - acc: 0.5678\n",
            "Epoch 57/300\n",
            "210282/210282 [==============================] - 64s 304us/sample - loss: 1.8693 - acc: 0.5739\n",
            "Epoch 58/300\n",
            "210282/210282 [==============================] - 63s 302us/sample - loss: 1.8319 - acc: 0.5822\n",
            "Epoch 59/300\n",
            "210282/210282 [==============================] - 64s 306us/sample - loss: 1.7996 - acc: 0.5889\n",
            "Epoch 60/300\n",
            "210282/210282 [==============================] - 64s 306us/sample - loss: 1.7609 - acc: 0.5962\n",
            "Epoch 61/300\n",
            "210282/210282 [==============================] - 65s 308us/sample - loss: 1.7253 - acc: 0.6036\n",
            "Epoch 62/300\n",
            "210282/210282 [==============================] - 66s 313us/sample - loss: 1.6970 - acc: 0.6087\n",
            "Epoch 63/300\n",
            "210282/210282 [==============================] - 66s 313us/sample - loss: 1.6671 - acc: 0.6152\n",
            "Epoch 64/300\n",
            "210282/210282 [==============================] - 66s 312us/sample - loss: 1.6282 - acc: 0.6234\n",
            "Epoch 65/300\n",
            "210282/210282 [==============================] - 66s 312us/sample - loss: 1.6025 - acc: 0.6292\n",
            "Epoch 66/300\n",
            "210282/210282 [==============================] - 66s 312us/sample - loss: 1.5764 - acc: 0.6331\n",
            "Epoch 67/300\n",
            "210282/210282 [==============================] - 65s 309us/sample - loss: 1.5460 - acc: 0.6400\n",
            "Epoch 68/300\n",
            "210282/210282 [==============================] - 65s 310us/sample - loss: 1.5167 - acc: 0.6461\n",
            "Epoch 69/300\n",
            " 46848/210282 [=====>........................] - ETA: 51s - loss: 1.3917 - acc: 0.6796Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRqzN2iAXSgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dump(tokenizer, open('drive/My Drive/dataset/tokenizer.pkl', 'wb'))\n",
        "model.save('drive/My Drive/dataset/model_weights.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff-nOV9iXWnH",
        "colab_type": "code",
        "outputId": "cbb95659-ce64-4d23-83cb-407234857640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "\n",
        "pickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))\n",
        "model.save('model_weights.hdf5')\n",
        "from google.colab import files\n",
        "files.download('tokenizer.pkl')\n",
        "files.download('model_weights.hdf5')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-30130e694b60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weights.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizer.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_weights.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFENmP8pb8nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dump(reverse_word_map, open('drive/My Drive/dataset/reverse_word_map.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZZGp-BYjOYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}